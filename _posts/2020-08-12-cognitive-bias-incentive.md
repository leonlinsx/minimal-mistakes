---
title:  "When paying for performance doesn't work"  
tags: [pay, incentives, bias, research]
published: false
---

### Takeaway

Getting paid more increases effort but not necessarily performance

<style>
      .iframe-container {
        overflow: hidden;        
        padding-top: 50%; <!-- Calculated from the aspect ration of the content (in case of 16:9 it is 9/16= 0.5625) -->
        position: relative;
      }
      .iframe-container iframe { 
         border: 0;
         height: 100%; <!-- Finally, width and height are set to 100% so the iframe takes up 100% of the containers space. -->
         left: 0;
         position: absolute;
         top: 0;
         width: 100%;
         display: block;
         margin: 0 auto; <!-- center image -->
      }
      <!-- 4x3 Aspect Ratio -->
      .iframe-container-4x3 {
        padding-top: 75%;
      }
</style> 

<div class="iframe-container-4x3">
  <p align="center"><iframe src="https://avoidboringpeople.substack.com/embed" frameborder="0" scrolling="no"> </iframe></p>
</div>

### Does performance change with incentives?

Imagine you had to solve a math problem. Do you think your performance would be better if you got a $10 reward for solving it? What about a $1,000 reward? 

We like to think that getting more money better incentives us, leading us to put in more effort and get better results. For example, one theory of high executive pay is that they're being paid for their better decision making \[1\]. Does getting a higher monetary reward actually help them make better decisions?

If it involves avoiding cognitive biases, probably not. Researchers found that people have the same incorrect biases, whether offered a low reward or a high one. This might mean that monetary rewards do not have as large an influence on decision quality as we think. 

In their paper ["Cognitive Biases: Mistakes or Missing Stakes?",](https://www.ifo.de/DocDL/cesifo1_wp8168.pdf "pdf") the researchers \[2\] look into how performance on tests is affected by the stakes. The question they wanted to answer was: Do people tend to make better decisions when the stakes are high?

What they ended up finding was that **people make the same types of cognitive bias errors whether they were offered low or high rewards.** 

Although their amount of effort increased, the actual scores were similar in both cases. This implies that it's not lack of effort, but the "right way of looking at a problem" causing people to fail at cognitive bias questions. Reframing is more important than paying.

Applied to decision making, this could mean that having higher stakes doesn't improve performance. You could pay your executives well, but don't expect that to induce better decision making.

Below, I go into the details of the experiment and end with a few follow up questions.

#### Experiment details

They chose to test using 4 types of commonly researched biases below \[3\]. I have a section explaining each bias and how it was tested for later.

1. Intuitive reasoning vs effortful deliberation (cognitive reflection)
2. Anchoring (overly relying on early info)
3. Failure of contingent thinking 
4. Base rate neglect (underweighting prior probability)

The experiment wanted to see behaviour under high monetary stakes. To run the experiment cost effectively, they conducted it in the Busara Center for Behavioral Economics in Nairobi, Kenya. This way, they could offer participants a large amount in local purchasing power, while still keeping costs down e.g. offer a month's salary as a reward \[4\]

Researchers first gave the N = 1,236 participants the test without any bonus reward. Then, the researchers told the participants there would be bonus rewards available for doing better on the next test. 

They measured performance and response times as dependent variables against the type of incentive. Performance was measured by percentage of responses on the test correct for that bias category, and response time was the average response time to questions of that bias category. e.g. you could get 80% correct and an average 20s response time to base rate neglect types of questions.

#### Biases

Those familiar with the biases mentioned above can skip straight to the results section, though this might be a good refresher. I'll start with biases that are easier to explain

##### 1. Intuitive reasoning

There are some types of questions that seem to have an intuitive answer on first sight, but the intuitive answer is wrong. If you put in more effort to think about the question, you can usually get it right.

For example: A bat and a ball cost $110 in total. The bat costs $100 more than the ball. How much does the ball cost?

The first answer most people think of is $10. But that's not right, since it's actually $5 for the ball and $105 for the bat, for a total cost of $110. 

Similar types of questions were used to test for this bias.

##### 2. Anchoring

Before reading the next question, think of the first two digits of the year of your birth.

Now, take a guess: Is the time (in minutes) it takes for light to travel from the Sun to the planet Jupiter more than or less than those digits? 

How many minutes does it take light to travel from the Sun to the planet Jupiter?

If you're like most people, you would have been anchored to the year of your birth while guessing the answer, and estimated a number that was closer to the year than it should be. Although your year of birth has no relation to the answer at all, people still take into account that initial starting number when estimating. [(The answer is 43 min btw)](https://image.gsfc.nasa.gov/poetry/venus/q89.html#:~:text=Mercury%200.387%20193.0%20seconds%20or,or%20159.6%20minutes%20Neptune%2030.058 "nasa")

Researchers used similar questions to see if participants made better guesses or guesses that were anchored, whether or not they got higher incentives \[5\].

##### 3. Failure of contingent thinking

There are some questions that require people to think about hypothetical contingencies, "what ifs." There is both an abstract way of presenting the problem, and a more concrete way that people do better on. I'll explain both.

Abstract version: Suppose someone tells you he has a deck of cards. These cards have odd or even numbers on one side, and brown or green colours on the other. Your friend shows you the four cards below, and also claims that "all cards with an even number on one side are green on the other"

What is the minimum number of cards you have to turn over to check if he's telling the truth?

![post]({{ site.url }}{{ site.baseurl }}/assets/images/Stake 3.png)

You need to turn over 8, since if 8 has a brown back, the claim is false. 

People often think they have to turn over green, but that card is irrelevant. Even if it showed an odd number, that doesn't give evidence to the claim. Remember, the claim is only about even numbers. 

You also need to turn over brown. If brown shows an even number, that let's you disprove the claim as well.

As you can see, the solution requires a bit more thinking beyond just intuition.

Concrete version: Suppose you're a bartender and enforce a min 18 years drinking law. The cards below either represent the drink a person is having, or the age of a person. Which people do you need to check?

![post]({{ site.url }}{{ site.baseurl }}/assets/images/Stake 4.png)

For some reason, this is easier for most people to solve. You need to check the person drinking beer, and you need to check the 16 year old person's drink.

The researchers used similar tests, framed both ways, in evaluating participants.

##### 4. Base rate neglect

Like the previous bias, this one also has a more abstract and concrete way of thinking about it. Base rate neglect is when people [fail to consider the underlying probability when making guesses](https://thedecisionlab.com/biases/base-rate-fallacy/ "base")

Abstract version: 1% of women have breast cancer. If a woman has breast cancer, the chance of her getting a positive test is 80%. If a woman does not have breast cancer, the chance of her getting a positive test is 9.6% (since tests aren't always accurate). 

A woman gets a positive test. What's the probability she actually has cancer?

Most people answer some high number. To show why that's wrong, let's look at the more concrete, intuitive version:

10 out of every 1000 women have breast cancer. 8 out of every 10 women with breast cancer get a positive test. 95 out of every 990 women without breast cancer get a positive test.

In a new representative sample of 100 women who all got positive tests, how many do you expect to actually have breast cancer?

You can see that the right math to do here is 8 out of (8 + 95), which is about 7.8 people (7.8%). The proportions in the intuitive version are the same as the abstract example, so the answer is the same as well. I'll skip the math for the first example but you can look at an explanation [here](https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/ "expl")

Researchers tested both versions of those wordings above as well.

#### Results

The researchers looked at participant performance on all those tests above, and whether offering a higher reward helped.

What they found was that for many tests, the higher incentive amount doesn't reduce cognitive biases. In the image below, each graph is one type of cognitive bias test. The top left is the test for 1 - Intuitive reasoning, top right for 4 - Base rate, bottom left for 3 - Contingent reasoning, bottom right for 2 - Anchoring.

Within each graph is the three incentive types given - none, standard, and high. The performance on each is shown. In many of the experiments, there's no increase in performance, moving from the "standard incentive" tick mark to the "high incentive" tick mark.

![post]({{ site.url }}{{ site.baseurl }}/assets/images/Stake 2.png)

And when looking at response times, a proxy for effort, they found that people did put in more effort when the incentive amount increased. In the graphs below, you can see the "high incentive" sections all being higher than the "standard incentive" sections, implying people took longer to think when they were given more money. However, that amount of effort didn't translate to actual performance.

![post]({{ site.url }}{{ site.baseurl }}/assets/images/Stake 1.png)

#### Follow up questions

1. Can we relate performance on cognitive bias tests to general decision making? Does getting better at the former imply getting better at the latter?
2. How do you measure performance for general decision making? What is the best decision?
3. Why is there an increase in intuitive contingency reasoning performance at higher stakes?
4. Does the limited time to respond nature of the experiment affect carry-over of results into the real world?
5. Should we recommend to give people higher incentives even though there's low effectiveness on performance?

### Footnotes

1. Or the cost to replace them
2. Benjamin Enke, Uri Gneezy, Brian Hall, David Martin, Vadim Nelidov, Theo Offerman, Jeroen van de Ven 
3. Reasoning for these 4 was "(i) the tasks that underlie these biases have an objectively correct answer; (ii) the biases are cognitive in nature, rather than preference-based; (iii) standard experimental instructions to measure these biases are short and simple, which helps rule out confusion resulting from complex instructions; and (iv) these biases all have received much attention and ample experimental scrutiny in the literature
4. The maximum bonus could be 130 KSh ($1.30) and 13,000 KSh ($130), vs Median monthly income of 10,000â€“12,000 KSh ($100)
5. They randomised the anchors to be either low or high, and the questions had answers that were rangebound from 0 to 100. This made measuring the effect of the anchor easier

*If you liked this, sign up for my [finance and tech newsletter:](https://avoidboringpeople.substack.com/ "ABP")*

<div class="iframe-container-4x3">
  <p align="center"><iframe src="https://avoidboringpeople.substack.com/embed" frameborder="0" scrolling="no"> </iframe></p>
</div>
